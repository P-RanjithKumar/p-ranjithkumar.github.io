<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Blog 3 | Ranjith Kumar</title>
  <style>
    /* Reuse existing styles from homepage */
    :root {
      --primary-color: #2d3436;
      --accent-color: #0984e3;
      --text-color: #2d3436;
      --hover-color: #74b9ff;
    }
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    body {
      font-family: 'Segoe UI', system-ui, sans-serif;
      line-height: 1.6;
      color: var(--text-color);
      margin: 0 auto;
      padding: 20px;
      max-width: 1200px;
    }

    /* Fixed Scroll Progress Indicator */
    .scroll-progress {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 4px;
      background: #eee;
      z-index: 1000;
    }
    .progress-bar {
      width: 0%;
      height: 100%;
      background: var(--accent-color);
    }

    /* Post Header */
    .post-header {
      margin-bottom: 3rem;
      position: relative;
      padding-top: 10px;
    }
    .back-to-blog {
      display: inline-flex;
      align-items: center;
      gap: 0.5rem;
      text-decoration: none;
      color: var(--accent-color);
      margin-bottom: 2rem;
      transition: color 0.2s ease;
    }
    .back-to-blog:hover {
      color: var(--hover-color);
    }
    .post-meta {
      display: flex;
      gap: 15px;
      color: #636e72;
      font-size: 0.9em;
      margin: 1rem 0;
    }

    /* Post Content */
    .post-content {
      display: grid;
      grid-template-columns: 1fr 250px;
      gap: 2rem;
    }
    .article-body {
      max-width: 800px;
      font-size: 1.1em;
      line-height: 1.8;
    }
    .article-body img {
      width: 100%;
      height: auto;
      border-radius: 8px;
      margin: 2rem 0;
    }
    .article-body h2,
    .article-body h3 {
      margin: 2rem 0 1rem;
      color: var(--primary-color);
    }
    blockquote {
      border-left: 4px solid var(--accent-color);
      padding: 1rem 2rem;
      margin: 2rem 0;
      background: #f8f9fa;
      border-radius: 0 8px 8px 0;
    }

    /* Table of Contents */
    .toc {
      position: sticky;
      top: 20px;
      align-self: start;
      padding: 1.5rem;
      background: #f8f9fa;
      border-radius: 8px;
    }
    .toc ul {
      list-style: none;
      padding-left: 1rem;
    }
    .toc a {
      color: var(--text-color);
      text-decoration: none;
      transition: color 0.2s ease;
      display: block;
      padding: 0.3rem 0;
    }
    .toc a:hover {
      color: var(--accent-color);
    }

    /* Post Navigation */
    .post-navigation {
      margin: 4rem 0;
      display: flex;
      justify-content: space-between;
      border-top: 1px solid #eee;
      padding-top: 2rem;
    }
    .nav-button {
      padding: 12px 25px;
      text-decoration: none;
      border-radius: 25px;
      transition: all 0.2s ease;
    }
    .prev-post {
      background: var(--accent-color);
      color: white;
    }
    .next-post {
      background: #f1f2f6;
      color: var(--text-color);
    }
    .nav-button:hover {
      transform: translateY(-2px);
    }

    /* Social Sharing */
    .social-sharing {
      margin: 2rem 0;
      display: flex;
      gap: 1rem;
    }
    .social-button {
      padding: 8px 20px;
      border-radius: 25px;
      text-decoration: none;
      display: flex;
      align-items: center;
      gap: 0.5rem;
      transition: transform 0.2s ease;
    }
    .twitter { background: #1DA1F2; color: white; }
    .linkedin { background: #2867B2; color: white; }
    .facebook { background: #4267B2; color: white; }

    /* New Math Section Styles */
    .math-section {
      font-family: 'Segoe UI', system-ui, sans-serif;
    }
    
    .math-card {
      background: linear-gradient(145deg, #ffffff, #f5f7fa);
      border-radius: 12px;
      padding: 24px;
      margin: 20px 0;
      box-shadow: 0 4px 15px rgba(0, 0, 0, 0.05);
    }
    
    .math-formula {
      background: #fff;
      padding: 20px;
      border-radius: 8px;
      border-left: 4px solid #0984e3;
      margin: 15px 0;
      font-size: 1.1em;
    }
    
    .math-breakdown {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
      gap: 20px;
      margin: 20px 0;
    }
    
    .math-component {
      background: #f8fafc;
      padding: 15px;
      border-radius: 8px;
      transition: transform 0.2s ease;
    }
    
    .math-component:hover {
      transform: translateY(-2px);
    }
    
    .math-title {
      color: #0984e3;
      font-weight: 600;
      margin-bottom: 8px;
    }

    /* Responsive Design */
    @media (max-width: 768px) {
      .post-content {
        grid-template-columns: 1fr;
      }
      .toc {
        position: static;
        margin-bottom: 2rem;
      }
      .post-navigation {
        flex-direction: column;
        gap: 1rem;
      }
      .math-breakdown {
        grid-template-columns: 1fr;
      }
    }
  </style>
</head>
<body>
  <!-- Scroll Progress Indicator -->
  <div class="scroll-progress">
    <div class="progress-bar"></div>
  </div>

  <header class="post-header">
    <a href="bloghome.html" class="back-to-blog">‚Üê Back to Blog</a>
    <h1>How I learnt Deep Learning and LLMs: A Tale of Code, Curiosity, and Andrej Karpathy</h1>
    <div class="post-meta">
      <span>Feb 23, 2025</span>
      <span>‚Ä¢</span>
      <span>10 min read</span>
    </div>
    <div class="post-tags">
      <span class="tag">Deep Learning</span>
      <span class="tag">Blogging</span>
    </div>
  </header>
  
  <div class="post-content">
    <article class="article-body">
      <!-- Cover Image -->
      <img src="assets/blog_cover_image/neuralnetwork.png" alt="Blog post cover image" style="border-radius: 8px; width: 800px; height: 150px;">
  
      <!-- Introduction -->
      <p>Hey there! I‚Äôm Ranjith Kumar, and today I‚Äôm taking you on a journey‚Äîfrom my first steps in deep learning to wrestling with large language models (LLMs) and even dipping my toes into reinforcement learning (RL). It‚Äôs been a wild ride of late-night coding, GPU rentals, and a YouTube obsession that changed everything. If you‚Äôre curious about how LLMs work, what makes attention mechanisms tick, or why RL is suddenly my new jam, you‚Äôre in the right place. Let‚Äôs break it all down, step by step, with plenty of visuals and beginner-friendly explanations along the way.</p>
  
      <!-- Section 1 -->
      <h2 id="section1">1. The Spark: PyTorch, Python, and a Hunger to Learn</h2>
      <p>Like many of you, my deep learning journey started with the basics: Python and PyTorch. In college, I learned just enough to build simple neural networks‚Äîbut let‚Äôs be honest, I was the kid tweaking code and praying it wouldn‚Äôt crash. The real magic happened outside class, down the YouTube rabbit hole. I devoured tutorials on LLMs, trying to understand how models like GPT churn out human-like text. Most videos were decent, but they left me with more questions than answers. That is, until I found my deep learning hero: Andrej Karpathy.</p>
  
      <!-- Section 2 -->
      <h2 id="section2">2. Andrej Karpathy: The Teacher I Never Met</h2>
      <p>One day, I stumbled upon Andrej Karpathy‚Äôs video on GPT-2, and it was like the clouds parted. His chill, no-nonsense style made even the toughest concepts feel approachable. I became a fanboy overnight, binging everything he‚Äôd ever posted. Thanks to Andrej, I finally cracked two of the trickiest parts of LLMs: <strong>attention mechanisms</strong> and <strong>tokenization</strong>. If you‚Äôre new to these terms, don‚Äôt worry‚Äîwe‚Äôre about to break them down together.</p>
      <!-- Section 3 -->
      <h2 id="section3">3. Attention Mechanisms: The Secret Sauce of LLMs</h2>
      <p>Let's start with attention mechanisms. Imagine you're reading this sentence: "The cat slept while the dog barked." Your brain naturally focuses on "cat" and "slept" to understand what's happening, right? Attention does the same for LLMs‚Äîit helps the model focus on the most important parts of the input when predicting the next word.</p>
      
      <!--  Math Section -->
      <div class="math-section">
        <div class="math-card">
          <p>The attention mechanism can be broken down into a simple formula that shows how different parts work together:</p>
          
          <div class="math-formula">
            <center>
              Attention(Q, K, V) = softmax(QK<sup>T</sup> / ‚àöd<sub>k</sub>) √ó V
            </center>
          </div>
          
          <div class="math-breakdown">
            <div class="math-component">
              <div class="math-title">Step 1: Similarity Score</div>
              <p>QK<sup>T</sup> measures how well each word matches with others - like finding connections between words.</p>
            </div>
            
            <div class="math-component">
              <div class="math-title">Step 2: Scaling (‚àöd<sub>k</sub>)</div>
              <p>We divide by ‚àöd<sub>k</sub> to keep numbers manageable - think of it as turning down the volume when it's too loud.</p>
            </div>
            
            <div class="math-component">
              <div class="math-title">Step 3: Softmax</div>
              <p>Converts scores into percentages (0-100%) showing how much attention each word should get.</p>
            </div>
            
            <div class="math-component">
              <div class="math-title">Step 4: Final Output</div>
              <p>Multiply by V to get the weighted result - like mixing ingredients based on their importance in a recipe.</p>
            </div>
          </div>
        </div>
        
        <div class="math-card">
          <h4>üí° Quick Example</h4>
          <p>Imagine processing the sentence "The cat chased the mouse":</p>
          <ul>
            <li>When focusing on "cat", the model pays more attention to "chased" (action)</li>
            <li>When focusing on "chased", it pays attention to both "cat" (subject) and "mouse" (object)</li>
            <li>This helps the model understand who did what to whom</li>
          </ul>
        </div>
      </div>

      <!-- Section 4 -->
      <h2 id="section4">4. Tokenization: Turning Words into Numbers</h2>
      <p>Before attention can do its thing, the model needs to ‚Äúread‚Äù the text. That‚Äôs where tokenization comes in. Tokenization chops text into smaller pieces called tokens‚Äîthink of them as the model‚Äôs vocabulary. For example:</p>
      <ul>
        <li>‚ÄúI love AI‚Äù might become [‚ÄúI‚Äù, ‚Äúlove‚Äù, ‚ÄúAI‚Äù].</li>
        <li>Trickier words like ‚Äúplaying‚Äù could split into [‚Äúplay‚Äù, ‚Äúing‚Äù] using subword tokenizers like BPE (Byte Pair Encoding).</li>
      </ul>
      <p>Each token gets a unique ID, and the model learns patterns from these IDs. Why‚Äôs this cool? It lets the model handle rare or new words by breaking them into familiar chunks. Imagine ‚Äúunbelievable‚Äù as [‚Äúun‚Äù, ‚Äúbeliev‚Äù, ‚Äúable‚Äù]‚Äîeven if it‚Äôs never seen the full word, it can guess the meaning. Tokenization is the first step in turning messy human language into something a machine can process.</p>
      <img src="assets/content_images/tokenization.png" alt="tokenization image" style="width: 700px; height: 400px;">

      <!-- Section 5 -->
      <h2 id="section5">5. My First LLM: From Gibberish to ‚ÄúAlmost Chatbot‚Äù</h2>
      <p>Armed with Andrej‚Äôs teachings, I decided to build my own LLM. I rented a GPU (because my laptop would‚Äôve cried), slapped together a transformer in PyTorch, and got to work. I coded up multi-head attention‚Äîwhere the model runs attention multiple times in parallel to capture different relationships‚Äîand added positional encodings (more on those later). After training on a small dataset, my first output was‚Ä¶ well, gibberish. Think ‚Äúcat the the dog umm.‚Äù But with some tweaks to the learning rate and more data, it started forming actual sentences. Not chatbot-level, but I was stoked.</p>
      <p>Andrej mentioned in one video that to make an LLM chatty, you need to fine-tune it on conversational data. I haven‚Äôt gotten there yet, but it‚Äôs on my to-do list. For now, I‚Äôm just happy I didn‚Äôt break anything.</p>
  
      <!-- Section 6 -->
      <h2 id="section6">6. The RL Detour: DeepSeek R1 and a Whole New World</h2>
      <p>Just when I thought I was getting comfy with LLMs, I stumbled across DeepSeek R1, a reasoning model that uses GRPO (Generalized Reward Policy Optimization). Cue the confusion‚ÄîRL? What‚Äôs that? I‚Äôd barely scratched the surface, but suddenly I was diving headfirst into reinforcement learning. GRPO led me to PPO (Proximal Policy Optimization), the HER paper (Hindsight Experience Replay), curiosity learning, and more. RL was a beast, but I couldn‚Äôt look away.</p>
      <h3>Reinforcement Learning: Teaching Machines to Learn by Doing</h3>
      <p>Let‚Äôs break down RL for beginners. Imagine teaching a dog to fetch: you reward it with treats when it brings the ball and ignore it when it doesn‚Äôt. Over time, the dog learns that fetching = treats. RL works similarly: an agent takes actions in an environment, gets rewards (or penalties), and learns to maximize its total reward.</p>
      <p>Here are the core pieces:</p>
      <ul>
        <li><strong>Agent</strong>: The learner (e.g., a model or robot).</li>
        <li><strong>Environment</strong>: The world the agent interacts with.</li>
        <li><strong>Policy (œÄ)</strong>: The strategy the agent uses to pick actions‚Äîlike ‚Äúif I‚Äôm here, do this.‚Äù</li>
        <li><strong>Reward Function</strong>: Defines what‚Äôs good or bad (e.g., +1 for fetching, -1 for ignoring).</li>
        <li><strong>Value Function</strong>: Estimates how good a state is in the long run.</li>
      </ul>
      <p>Unlike supervised learning, where you have labeled data, RL is all about trial and error. The agent explores, fails, and learns‚Äîlike me trying to bake without a recipe. It‚Äôs slow and messy, but when it works, you‚Äôve got a model that can play games, optimize schedules, or even drive cars.</p>
  
      <!-- Section 7 -->
      <h2 id="section7">7. Transformers: The Engine Behind LLMs</h2>
      <p>Now, let‚Äôs zoom back to LLMs and unpack the transformer architecture‚Äîthe real MVP. Born from the ‚ÄúAttention is All You Need‚Äù paper, transformers ditched recurrent networks (RNNs) and went all-in on attention. Here‚Äôs how they work:</p>
      <ul>
        <li><strong>Encoder</strong>: Takes the input (tokenized text), runs it through multiple layers of attention and feed-forward networks, and produces rich embeddings that capture the meaning of each token in context.</li>
        <li><strong>Decoder</strong>: Uses the encoder‚Äôs output plus its own attention to generate text, one token at a time. It‚Äôs autoregressive, meaning it predicts the next word based on the previous ones.</li>
        <li><strong>Multi-Head Attention</strong>: Runs attention multiple times in parallel, each ‚Äúhead‚Äù focusing on different aspects (like grammar or meaning).</li>
        <li><strong>Positional Encodings</strong>: Since transformers don‚Äôt process sequentially, we add sine and cosine waves to the token embeddings to encode word order. Without this, ‚Äúcat chased dog‚Äù and ‚Äúdog chased cat‚Äù would look the same to the model!</li>
      </ul>
      <img src="assets/content_images/transformers.png" alt="transformer image">
      <p>Why are transformers so powerful? They process everything in parallel, making them fast, and attention lets them handle long-range dependencies. It‚Äôs why my baby LLM could eventually string sentences together, even if it‚Äôs not quite ready for prime time.</p>
  
      <!-- Section 8 -->
      <h2 id="section8">8. What‚Äôs Next? Fine-Tuning and RL Domination</h2>
      <p>I‚Äôm not done yet. My LLM needs fine-tuning on conversational data to chat like a human instead of a weird robot poet. And RL? I‚Äôve got policy optimization on deck‚Äîmore algorithms, more math, more coffee. The journey‚Äôs just heating up, and I‚Äôm here for it.</p>
  
      <!-- Section 9 -->
      <h2 id="section9">9. Your Turn!</h2>
      <p>Whew, you made it! If you‚Äôre into deep learning, LLMs, or RL, let‚Äôs geek out together. What‚Äôs your go-to resource? Any RL tricks up your sleeve? Drop a comment or ping me on socials:</p>
      <ul>
        <li><a href="https://www.linkedin.com/in/ranjith-kumar-b66180250">LinkedIn</a></li>
        <li><a href="https://www.instagram.com/ranjithh_56">Instagram</a></li>
        <li><a href="https://github.com/P-RanjithKumar">Github</a></li>
      </ul>
      <p>Keep coding, stay curious, and embrace the chaos‚Äîit‚Äôs where the good stuff happens!</p>
  
      <!-- Post Navigation -->
      <div class="post-navigation">
        <a href="blog2.html" class="nav-button prev-post">‚Üê Previous Post</a>
        <a href="blog4.html" class="nav-button next-post">Next Post ‚Üí</a>
      </div>
    </article>
  
    <!-- Table of Contents -->
    <aside class="toc">
      <h3>Table of Contents</h3>
      <ul>
        <li><a href="#section1">The Spark: PyTorch, Python, and a Hunger to Learn</a></li>
        <li><a href="#section2">Andrej Karpathy: The Teacher I Never Met</a></li>
        <li><a href="#section3">Attention Mechanisms: The Secret Sauce of LLMs</a></li>
        <li><a href="#section4">Tokenization: Turning Words into Numbers</a></li>
        <li><a href="#section5">My First LLM: From Gibberish to "Almost Chatbot"</a></li>
        <li><a href="#section6">The RL Detour: DeepSeek R1 and a Whole New World</a></li>
        <li><a href="#section7">Transformers: The Engine Behind LLMs</a></li>
        <li><a href="#section8">What's Next? Fine-Tuning and RL Domination</a></li>
        <li><a href="#section9">Your Turn!</a></li>
      </ul>
    </aside>
  </div>

  <!--###############################################################################################################-->

  <script>
    // Scroll Progress Indicator Update
    window.addEventListener('scroll', () => {
      const winScroll = document.body.scrollTop || document.documentElement.scrollTop;
      const height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
      const scrolled = (winScroll / height) * 100;
      document.querySelector('.progress-bar').style.width = scrolled + "%";
    });

    // Smooth Scroll for Table of Contents
    document.querySelectorAll('.toc a').forEach(anchor => {
      anchor.addEventListener('click', function(e) {
        e.preventDefault();
        const section = document.querySelector(this.getAttribute('href'));
        section.scrollIntoView({ behavior: 'smooth' });
      });
    });

    // Estimated Reading Time
    const postContent = document.querySelector('.article-body');
    const words = postContent.innerText.split(' ').length;
    const readingTime = Math.ceil(words / 200);
    document.querySelector('.post-meta span:nth-child(5)').innerHTML = 
      `${readingTime} min read`;
  </script>
</body>
</html>
